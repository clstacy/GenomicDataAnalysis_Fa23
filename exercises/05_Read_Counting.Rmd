---
title: "Read Counting"
author: "Carson Stacy & Jeffrey Lewis"
date: "Fall 2023"
output: html_document
---

last updated: `r Sys.Date()`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
set.seed("1492")
```

As usual, make sure we have the right packages for this exercise

```{r ready-packages}
if (!require("pacman")) install.packages("pacman"); library(pacman)

# let's load all of the files we were using and want to have again today
p_load("tidyverse", "knitr", "readr",
       "pander", "BiocManager", 
       "dplyr", "stringr")

# We also need the Bioconductor packages "Rsubread" for today's activity.
p_load("Rsubread")
```

Previously, we aligned our fastq files to the reference genome, generating BAM files. They should be in your "\~/Desktop/Genomic_Data_Analysis/Data/Trimmed_rfastp" folder, unless you chose a different place to store them.

```{r}
# Where the bam files are located (default same as trimmed fastq file location)
bam_file_dir <- "~/Desktop/Genomic_Data_Analysis/Data/Trimmed_rfastp/"

# save list of all of those files with their full path
bam.files <- list.files(path = bam_file_dir, 
                                  pattern = ".subread.BAM$", 
                                  full.names = TRUE)
# make sure we see what we expect.
bam.files
```

You should see the full paths to all 16 trimmed fastq bam files that we will be mapping to the reference genome today.

# Read Counting

We currently have our raw reads mapped to the genome in the form of bam files. Before the differential expression analysis can proceed, these reads must be assigned and counted towards annotated genes. This can be achieved with functions in the Rsubread package, we all also see how to do this with Salmon.

## Retrieve the genome annotation

We will use a bash code chunk to download the latest genome annotation

```{bash fetchGenome}
# Define the destination file path
REF_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Reference"
# If this directory doesn't exist, you need to first complete the Read_Mapping.Rmd exercise. 

# Define the URL of reference genome annotation (gtf)
# (latest from ensembl)
url="ftp://ftp.ensembl.org/pub/release-110/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz"

# Check if the file already exists at the destination location
if [ ! -f "$REF_DIR/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz" ]; then
    echo "Reference genome annotation not found, downloading..."
    # If the file does not exist, download it using curl
    curl -o "$REF_DIR/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz" "$url"
    echo "Downloading finished"
else
    echo "File already exists at $REF_DIR Skipping download."
fi
```

Let's take a look at the first few lines of the gtf file

```{r seeGTF}
# see the header columns with metadata starting with #! and delimited with \t
read_csv("~/Desktop/Genomic_Data_Analysis/Reference/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz", 
    col_names = FALSE) %>% head(10)

# We can also take a look at the first few entries to see the columns
read_tsv("~/Desktop/Genomic_Data_Analysis/Reference/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz", 
    col_names = FALSE,  comment = "#", trim_ws = TRUE) %>% head(20)
```

There are 9 columns in a standard gtf file, information about each is available here: <https://useast.ensembl.org/info/website/upload/gff.html>

Note that version 2 of gff is identical to the gtf format.

## Counting with FeatureCounts

```{r}
library(Rsubread)

# Set path of the reference annotation gzipped gtf file
reference_annotation = "~/Desktop/Genomic_Data_Analysis/Reference/Saccharomyces_cerevisiae.R64-1-1.110.gtf.gz"
```

We can see the arguments available with the align function from the Rsubread package

```{r argsCount}
args(featureCounts)
```

The Phred offset determines the encoding for the base-calling quality string in the FASTQ file. For the Illumina 1.8 format onwards, this encoding is set at +33. However, older formats may use a +64 encoding. Users should ensure that the correct encoding is specified during alignment. If unsure, one can examine the first several quality strings in the FASTQ file. A good rule of thumb is to check whether lower-case letters are present (+64 encoding) or absent (+33).

```{r alignReads}
# This command counts the number of each feature per fastq file, 
#.  generating an output we can use later.
fc <- featureCounts(bam.files,
                    annot.ext = reference_annotation,
                    isGTFAnnotationFile = TRUE,
                    GTF.featureType = "exon"
                    )
```

We can see what all is stored in the featureCounts output object

```{r identifyComponents}
names(fc)
```

The statistics of the read mapping can be seen with `fc$stats`. This reports the numbers of unassigned reads and the reasons why they are not assigned (eg. ambiguity, multi-mapping, secondary alignment, mapping quality, fragment length, chimera, read duplicate, non-junction and so on), in addition to the number of successfully assigned reads for each library.

```{r}
fc$stat
```

## Counts

The counts for the samples are stored in fc\$counts.

We can look at the dimensions of the counts to see how many genes and samples are present. The first number is the number of genes and the second number is the number of samples.

```{r}
dim(fc$counts)
```

let's take a look at the first few lines of fc\$counts

```{r}
head(fc$counts)
```

The row names of the fc\$counts matrix represent the Systematic Name for each gene (can be Entrez gene identifiers for other organisms) and the column names are the output filenames from calling the align function.

The annotation slot shows the annotation information that featureCounts used to summarise reads over genes.

```{r}
head(fc$annotation)
```

# Saving `fc` object for future use

We will need to use this object in our next class. We can use the R function `saveRDS()` to save the R object to your computer, so it can be accessed at a later date.

```{r save-fc}
# create a directory for the count output to go into if not already present
dir_output_counts <- path.expand("~/Desktop/Genomic_Data_Analysis/Data/Counts/Rsubread/")
if (!dir.exists(dir_output_counts)) {dir.create(dir_output_counts, recursive = TRUE)}

# save the R data object
saveRDS(object = fc, file = paste0(dir_output_counts,"rsubread.yeast_fc_output.Rds"))

# often, we want to share this file as a tsv file. Here is how we can do that:
write_tsv(data.frame(
            fc$annotation[,"GeneID"],
            fc$counts,
            stringsAsFactors=FALSE),
    file=paste0(dir_output_counts,"rsubread.gene_counts.merged.yeast.tsv"))
```

## RSubread also allows for some basic QC checking:

We can have a look at the quality scores associated with each base that has been called by the sequencing machine using the qualityScores function in Rsubread.

Let's extract quality scores for 50 reads for the fastq file .

```{r check-qualityScores}
# Extract quality scores
qs <- qualityScores(
  filename="~/Desktop/Genomic_Data_Analysis/Data/Trimmed_rfastp/YPS606_MSN24_ETOH_REP1_R1.fastq.gz",
                    nreads=50)

head(qs)
```

We are randomly sampling 50 reads from the file and seeing the quality scores. A quality score of 30 corresponds to a 1 in 1000 chance of an incorrect base call. (A quality score of 10 is a 1 in 10 chance of an incorrect base call.) To look at the overall distribution of quality scores across the sampled reads, we can look at a boxplot

```{r visualizeq-qs}
boxplot(qs)
```

# Salmon

Let's go through using salmon to count reads directly from the trimmed fastq.gz files

## Pseudomapping & counting

```{bash pseudoCount-salmon, engine.opts='-l'}
DATA_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Trimmed_rfastp"
SALMON_OUT_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Counts/Salmon"
SALMON_INDEX_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Reference/index_salmon_Saccharomyces_cerevisiae.R64-1-1"

# make the analysis directory if it doesn't already exist
mkdir -p $SALMON_OUT_DIR

# activate the salmon environment
conda activate salmon

# loop through all of the fastq files
for fn in $DATA_DIR/*.fastq.gz;
do
samp=`basename ${fn}`
echo "Processing sample ${samp}"

# run salmon
salmon quant -i $SALMON_INDEX_DIR -l A \
         -r ${fn} \
         --useVBOpt \
         -p 4 --validateMappings -o $SALMON_OUT_DIR/${samp}_quant
done

# combine all of the output files into a merged count matrix
salmon quantmerge --quants $SALMON_OUT_DIR/*_quant --column numreads -o $SALMON_OUT_DIR/salmon.gene_counts.merged.yeast.tsv 

# remove the _mRNA from gene name
sed -i '' -E 's/^([^\t]+)_mRNA(\t|$)/\1\2/' $SALMON_OUT_DIR/salmon.gene_counts.merged.yeast.tsv

# we can also create a table of tpm values per gene by changing the --column flag
salmon quantmerge --quants $SALMON_OUT_DIR/*_quant --column tpm \
          -o $SALMON_OUT_DIR/salmon.gene_tpm.merged.yeast.tsv

# remove the _mRNA from gene name
sed -i '' -E 's/^([^\t]+)_mRNA(\t|$)/\1\2/' $SALMON_OUT_DIR/salmon.gene_tpm.merged.yeast.tsv

conda deactivate
```

This script loops through each sample and invokes salmon using default mostly options. The `-i` argument tells salmon where to find the index `-l A` tells salmon that it should automatically determine the library type of the sequencing reads (e.g. stranded vs. unstranded etc.). The -r arguments tell salmon where to find the SE reads for this sample (notice, salmon will accept gzipped FASTQ files directly). Finally, the `-p 4` argument tells salmon to make use of 4 threads and the `-o` argument specifies the directory where salmon's quantification results should be written. The `â€“useVBOpt` flag sets to use variational Bayesian EM algorithm rather than the 'standard EM' to optimize abundance estimates (more accurate). Salmon exposes many different options to the user that enable extra features or modify default behavior. However, the purpose and behavior of all of those options is beyond the scope of this introductory tutorial. You can read about salmon's many options in the documentation.

# Activity

1.  Identify which gene has the highest counts across all samples for both salmon and Rsubread outputs.

2.  Redo the counting over the exons, rather than the genes (specify useMetaFeatures = FALSE) with RSubread. Use the bam files generated doing alignment reporting only unique reads, and call the featureCounts object fc.exon. Check the dimension of the counts slot to see how much larger it is.

3.  What differences do you notice in the count values from Salmon vs Rsubread?

4.  CHALLENGE: Download the full size fastq files from OneDrive & use Salmon to get the read counts on the non-subsampled files.

Be sure to knit this file into a pdf or html file once you're finished.

System information for reproducibility:

```{r}
pander::pander(sessionInfo())
```
