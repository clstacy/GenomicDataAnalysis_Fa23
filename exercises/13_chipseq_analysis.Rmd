---
title: "ChIP-seq Analysis"
author: "Carson Stacy & Jeffrey Lewis"
date: "Fall 2023"
output:
  html_document:
    code_folding: show
    embed-resources: true
editor_options:
  markdown:
    wrap: 72
---

last updated: `r Sys.Date()`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description

In this class exercise, we will practice analyzing ChIP-seq data.

## Learning Outcomes

At the end of this exercise, you should be able to:

-   

## Exercise Background

In this exercise, we will look at the only published ChIP-seq data for
Msn2/4 mutants under EtOH stress conditions similar to those we have
been exploring throughout this course. The data comes from []. We will
go through this analysis together, starting from the raw fastq files.

## Pre-Analysis Preparations

Before analyzing our ChIP-seq results, we need to prepare our computing
environment for this analysis.

### Prepare Software

This analysis will use both R and terminal based commands.

#### R packages

```{r ready-packages}
# Ensure required packages are installed
if (!require("pacman")) install.packages("pacman"); library(pacman)

# Load necessary packages
# p_load("tidyverse", "knitr", "readr", "pander", "BiocManager", 
#        "dplyr", "stringr", #"purrr", "reactable",
#        "biomaRt", "memes", "Biostrings", "curl", "universalmotif")

# library(biomaRt)
# library(memes)
# library(curl)
# library(universalmotif)
library(tidyverse)
library(ShortRead) # added by me, using rockerfeller approach.
p_install("ChIPQC")
p_install("ChIPseeker")
library(ChIPQC)
library(ChIPseeker)
# library(DiffBind)
library(clusterProfiler)
library(AnnotationDbi)
p_load("Rfastp", "Rsubread")
library(Rsubread)
library(Rfastp)
```

#### Conda environments

Similar to exercise 03_Working_with_Sequences.Rmd, we need to use
software that aren't available in R. One way to do that is the way shown
here, creating and activating conda environments. If you haven't done
set-up of conda on your system as described in exercise 03, this code
likely won't run for you.

##### FastQC

```{bash create-QCcondaEnvironment, engine.opts='-l'}
# create an enviornment for our QC packages
if conda info --envs | grep -q QC; then echo "environment 'QC' already exists"; else conda create -y -n QC fastqc multiqc; fi

# see available conda environments
conda env list

# activate our QC environment
conda activate QC

# make sure desired packages are working
which fastqc
which multiqc

# get the versions of each software
fastqc -v
multiqc --version

# it's always good coding practice to deactivate a conda environment at the end of a chunk
conda deactivate
```

##### MACS2

A popular software for peak-calling ChIP-seq data is
[MACS2](https://pypi.org/project/MACS2/). It uses a Poisson
distribution-based model to background identify significant peaks in
ChIP-seq data.

```{bash create-MACS2condaEnvironment, engine.opts='-l'}
# create an enviornment for our QC packages
if conda info --envs | grep -q MACS; then echo "environment 'MACS' already exists"; else conda create -y -n MACS macs2 -c bioconda; fi

# see available conda environments
conda env list

# activate our MACS environment
conda activate MACS

# make sure desired package is working
which macs2

# get the versions of each software
macs2 --version

# it's always good coding practice to deactivate a conda environment at the end of a chunk
conda deactivate
```

### Data Retreival

For today's exercise, the software Model-based Analysis of ChIP-seq (MACS) will be doing the ChIP-seq specific part of our analysis. MACS needs .bam files as input, which we can generate in the same way as we did in the 04_Read_Mapping.Rmd exercise. However, we get .fastq files from sequencing, so we have to align the fastq files to the genome. A supplement 

#### fastq files

We will be using paired-end fastq files from the publication
<https://academic.oup.com/nar/article/42/9/5468/1246885>, with
experiment SRA accession SRP033438. Specifically, we will be getting
time 0 minutes and time 20 minutes post glucose to glycerol shift, which
induces the ESR. These samples have the names SRR1181480 and SRR1181481
respectively.

We could use the SRA toolkit to download these files (tutorial
[here](https://erilu.github.io/python-fastq-downloader/#automating-downloads-using-python)).

An alternative approach we can use to download these files is going to
<https://www.ebi.ac.uk/ena/browser/view/SRR1181480> and
<https://www.ebi.ac.uk/ena/browser/view/SRR1181481> to either download
the files manually, or download the bash script that we can use to
download the files. We will use a modified version of that code to
download the files today.

```{bash fetch-fastq-chipseq}
# Be sure to change this file path to the path you want your data to go
RAW_DATA_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Raw/ChIP"
# if you're using Windows 10,
# in RStudio, go to Tools>Global Options... > Terminal > New Terminals open with...
# and choose WSL bash or git bash
# next, use: (be sure to put in the correct username)
#RAW_DATA_DIR="/mnt/c/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Raw"

# create the destination directory if it doesn't already exist
mkdir -p $RAW_DATA_DIR

# change to that directory (for this code chunk only)
cd $RAW_DATA_DIR
pwd
# Download the files.
# WARNING: curl doesn't work with relative paths

# T=0 read 1
if [ ! -f "$RAW_DATA_DIR/SRR1181480_1.fastq.gz" ]; then
    echo "fastq file SRR1181480_1.fastq.gz not found, downloading..."
    # If the file does not exist, download it using curl
    wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR118/000/SRR1181480/SRR1181480_1.fastq.gz
    echo "Downloading finished"
else
    echo "File SRR1181480_1.fastq.gz already exists at $RAW_DATA_DIR Skipping download."
fi

#T=0 read 2
if [ ! -f "$RAW_DATA_DIR/SRR1181480_2.fastq.gz" ]; then
    echo "fastq file SRR1181480_2.fastq.gz not found, downloading..."
    # If the file does not exist, download it using curl
    wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR118/000/SRR1181480/SRR1181480_2.fastq.gz
    echo "Downloading finished"
else
    echo "File SRR1181480_2.fastq.gz already exists at $RAW_DATA_DIR Skipping download."
fi

# T=20 read 1
if [ ! -f "$RAW_DATA_DIR/SRR1181481_1.fastq.gz" ]; then
    echo "fastq file SRR1181481_1.fastq.gz not found, downloading..."
    # If the file does not exist, download it using curl
    wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR118/001/SRR1181481/SRR1181481_1.fastq.gz
    echo "Downloading finished"
else
    echo "File SRR1181481_1.fastq.gz already exists at $RAW_DATA_DIR Skipping download."
fi

#T=20 read 2
if [ ! -f "$RAW_DATA_DIR/SRR1181481_2.fastq.gz" ]; then
    echo "fastq file SRR1181481_2.fastq.gz not found, downloading..."
    # If the file does not exist, download it using curl
    wget -nc ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR118/001/SRR1181481/SRR1181481_2.fastq.gz
    echo "Downloading finished"
else
    echo "File SRR1181481_2.fastq.gz already exists at $RAW_DATA_DIR Skipping download."
fi

# see all downloaded files
ls -lah
```

This process can take awhile, and analyzing the full size files takes more
time that we have in class.

We'll be using subsets of these files for our in-class exercise.
Subsampling reads can be problematic for ChIP-seq data, so we'll use
results of mapping the full data sets for our analysis. You are welcome
to try running this exercise with the full size files (available in
OneDrive folder) after class.

#### Reference files

\#####**Genome**

```{bash fetch-genome-chipseq}
# Define the destination file path
# You can change this file path to the path you want your data to go, or leave it.
REF_DIR="/Users/$USER/Desktop/Genomic_Data_Analysis/Reference"

# make that directory if it doesn't already
mkdir -p $REF_DIR

# Define the URL of reference genome
# (latest from ensembl)
url="ftp://ftp.ensembl.org/pub/release-110/fasta/saccharomyces_cerevisiae/dna/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz"


# Check if the file already exists at the destination location
if [ ! -f "$REF_DIR/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz" ]; then
    echo "Reference genome not found, downloading..."
    # If the file does not exist, download it using curl
    curl -o "$REF_DIR/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz" "$url"
    echo "Downloading finished"
else
    echo "File already exists at $REF_DIR Skipping download."
fi
```

\#####**blacklist**

I couldn't find an extensive blacklist/exclusion list for S. cerevesiae.
Will check and see if we find one..

### Quality Control

We can use **FastQC** to do quality control for fastq files generated in
ChIP-seq experiments.

### Trimming & create BAM files

Get paths to all of our read files
```{r}
# assign directory with the raw fastq files
fq_file_dir <- path.expand("~/Desktop/Genomic_Data_Analysis/Data/Raw/ChIP")

# assign read 1 and read 2 paths into objects
fq_read1_files <- list.files(fq_file_dir, full.names = TRUE, pattern = "*_1.fastq.gz")
fq_read2_files <- list.files(fq_file_dir, full.names = TRUE, pattern = "*_2.fastq.gz")
```

#### Trim with rfastp

```{r}
# create a directory for the output to go into if not already present
dir_trimmed.fq_files <- path.expand("~/Desktop/Genomic_Data_Analysis/Data/Trimmed/ChIP")
if (!dir.exists(dir_trimmed.fq_files)) {dir.create(dir_trimmed.fq_files, recursive = TRUE)}

# run rfastp on all fastq files
for (i in 1:length(fq_read1_files)) {
  # file path to each file for paired end reads
  read1 <- fq_read1_files[i]
  read2 <- fq_read2_files[i]
  # assign output file (putting it inside of dir_trimmed.fq_files folder)
  output_name <- paste0(dir_trimmed.fq_files,
                        "/",
                        basename(fq_read1_files[i])) |>
                          str_replace("_1", "")
  json_report <- rfastp(
    read1 = read1,
    read2 = read2,
    outputFastq = str_split(output_name, fixed("."))[[1]][1],
    disableTrimPolyG = FALSE,
    cutLowQualFront = TRUE,
    cutLowQualTail = TRUE,
    minReadLength = 15
  )
  
  # Print the output file link in the R Markdown document
  cat(paste0(
    "[Processing Complete - ",
    basename(output_name),
    "](",
    output_name,
    ")\n\n"
  ))
}
```

#### Map to Reference

```{r}
# find our trimmed fastq files
trimmed_fastq_files_R1 <- list.files(path = dir_trimmed.fq_files, 
                                  pattern = "_R1.fastq.gz$", 
                                  full.names = TRUE)


trimmed_fastq_files_R2 <- list.files(path = dir_trimmed.fq_files, 
                                  pattern = "_R2.fastq.gz$", 
                                  full.names = TRUE)

# print them out
trimmed_fastq_files_R1
trimmed_fastq_files_R2

```

Build RSubread Index Genome
```{r}
# Set path of the reference fasta file
reference_genome = path.expand("~/Desktop/Genomic_Data_Analysis/Reference/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz")

index_reference_genome = path.expand("~/Desktop/Genomic_Data_Analysis/Reference/index_rsubread_Saccharomyces_cerevisiae.R64-1-1")

# build the index
buildindex(basename=index_reference_genome, reference=reference_genome)
```


Run alignment

```{r}
# run the alignment on all of the trimmed_fastq_files
align(index=index_reference_genome, 
      readfile1=trimmed_fastq_files_R1,
      readfile2=trimmed_fastq_files_R2,
      type = "dna",
      input_format = "gzFASTQ",
      output_format = "BAM",
      unique = TRUE,
      nBestLocations = 1,
      sortReadsByCoordinates = TRUE,
      nthreads=6
      )

# align(index=index_reference_genome, 
#       readfile1=trimmed_fastq_files_R2,
#       type = "dna",
#       input_format = "gzFASTQ",
#       output_format = "BAM",
#       unique = FALSE,
#       nBestLocations = 1,
#       sortReadsByCoordinates = TRUE,
#       nthreads=6
#       )

# Create new directory to store mapping .bam files
dir_bam_files <- path.expand("~/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP")
if (!dir.exists(dir_bam_files)) {dir.create(dir_bam_files, recursive = TRUE)}
```

Move output files into bam file directory
```{bash}
trim_fq_dir=~/Desktop/Genomic_Data_Analysis/Data/Trimmed/ChIP
bam_dir=~/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP/
mv $trim_fq_dir/*.BAM* $bam_dir
```

Get paths to our bam files
```{r}
bam_files <- list.files(path = dir_bam_files, pattern = ".BAM$", full.names = TRUE)
bam_files
```

## Peak Calling

Now, we are able to call peaks with MACS2.

To run MACS2 to we need to supply:
      
    1. A BAM file to find enriched regions in. (specified after -t)
      a. (this is the only REQUIRED parameter for MACS)
    2. A Name for peak calls (specified after –name).
    3. An output folder to write peaks into (specified after –outdir).
    4. Optionally, but highly recommended, we can identify a control to compare to (specified after –c).


Let's first try running macs2 for each sample with no control
```{bash run-MACS2-chip, engine.opts='-l'}
# activate our MACS environment
conda activate MACS

macs_outdir=/Users/$USER/Desktop/Genomic_Data_Analysis/Analysis/ChIP/

# run macs on the 0 minutes sample, no control
macs2 callpeak -t /Users/$USER/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP/SRR1181480_R1.fastq.gz.subread.BAM \
  -n MSN24_ESR_t0_noControl \
  --outdir $macs_outdir \
  -f BAMPE \
  -g 1.2e7 \
  --nomodel \
  --extsize 50


# run macs on the 20 minutes sample, no control
macs2 callpeak -t "/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP/SRR1181481_R1.fastq.gz.subread.BAM" \
               -n MSN24_ESR_t20_noControl \
               --outdir $macs_outdir \
               -f BAMPE \
               -g 1.2e7 \
               -B \
               --nomodel \
               --extsize 50

# run macs with 20 min as treatment and 0 min as control
macs2 callpeak -t "/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP/SRR1181481_R1.fastq.gz.subread.BAM" \
               -n MSN24_ESR_t20vst0 \
               -c "/Users/$USER/Desktop/Genomic_Data_Analysis/Data/Bam/ChIP/SRR1181481_R1.fastq.gz.subread.BAM" \
               --outdir $macs_outdir \
               -B \
               -f BAMPE -g 1.2e7 #--nomodel --extsize 50 -w -S
               

# Rename all *.bdg to *.bedgraph for IGV 
for file in ${macs_outdir}*.bdg; do
   mv -- "$file" "${file%.bdg}.bedgraph"
done

```

### OPTIONAL: Assess Peak call quality using ChIPQC

Today, we will be using ChIPQC, a Bioconductor package that takes as
input BAM files and peak calls to automatically compute a number of
quality metrics and generates a ChIPseq experiment quality report. We
are going to use this package to generate a report for our Msn2/4
samples for 0 minutes and 20 minutes.

```{r}
# Load libraries
library(ChIPQC)

# Generate sample data
samples <- tribble(
  ~SampleID, ~Tissue, ~Factor,~Condition,~Replicate,~bamReads,~ControlID,~bamControl,~Peaks,~PeakCaller,~Spikein,
  "MSN24_ESR_t20vst0",  NA, NA, "ESR", 1, paste0(dir_bam_files,"/SRR1181481_R1.fastq.gz.subread.BAM"), "MSN24_ESR_t0", paste0(dir_bam_files,"/SRR1181480_R1.fastq.gz.subread.BAM"), "~/Desktop/Genomic_Data_Analysis/Analysis/ChIP/MSN24_ESR_t20vst0_peaks.xls", "macs", NA
)
View(samples)
```

for later: "~/Desktop/Genomic_Data_Analysis/Analysis/ChIP/MSN24_ESR_t20vst0_peaks.xls"

The sample sheet contains metadata information for the dataset. Each row
represents a peak set (which in most cases is one ChIP sample) and
several columns of required information, which allows us to easily load
the associated data in one single command. NOTE: The column headers have
specific names that are expected by ChIPQC!!.

1.  SampleID: Identifier string for sample

2.  Tissue, Factor, Condition: Identifier strings for up to three
    different factors (You will need to have all columns listed. If you
    don't have infomation, then set values to NA)

3.  Replicate: Replicate number of sample

4.  bamReads: file path for BAM file containing aligned reads for ChIP
    sample

5.  ControlID: an identifier string for the control sample

6.  bamControl: file path for bam file containing aligned reads for
    control sample

7.  Peaks: path for file containing peaks for sample

8.  PeakCaller: Identifier string for peak caller used. Possible values
    include "raw", "bed", "narrow", "macs"

Next we will create a ChIPQC object which might take a few minutes to
run. ChIPQC will use the samplesheet read in the data for each sample
(BAMs and narrowPeak files) and compute quality metrics. The results
will be stored into the object.

```{r}
p_install("TxDb.Scerevisiae.UCSC.sacCer3.sgdGene")
BiocManager::install("ChIPpeakAnno")
# set up custom anno for QC results
library(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)
library(GenomicRanges)
library(ChIPpeakAnno)
yGR <- toGRanges(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)

customAnno <- list(version="sacCer3", Test=yGR)

QCresult <- ChIPQCsample(reads = paste0(dir_bam_files,"/SRR1181480_R1.fastq.gz.subread.BAM"),
                         peaks = "~/Desktop/Genomic_Data_Analysis/Analysis/ChIP/MSN24_ESR_t20vst0_peaks.xls",
                         annotation = customAnno)

QCresult |> fragmentlength()

QCresult

ChIPQCreport(QCresult)

plotCC(QCresult)
plotRegi(QCresult)

## Create ChIPQC object
chipObj <- ChIPQC(samples)#,# annotation="hg19") 

# Create ChIPQC report
ChIPQCreport(chipObj, reportName="ChIP QC report: Msn2/4", reportFolder="ChIPQCreport")
```

## Working with Peaks

```{r}
library(GenomicRanges)
macsPeaks <- "~/Desktop/Genomic_Data_Analysis/Analysis/ChIP/MSN24_ESR_t20vst0_peaks.xls"
macsPeaks_DF <- read.delim(macsPeaks,comment.char="#")
macsPeaks_GR <- GRanges(seqnames=macsPeaks_DF[,"chr"],
                        IRanges(macsPeaks_DF[,"start"],macsPeaks_DF[,"end"]))
mcols(macsPeaks_GR) <- macsPeaks_DF[,c("abs_summit", "fold_enrichment")]
macsPeaks_GR
```
```{r}
library(ChIPseeker)
peakAnno <- annotatePeak(macsPeaks_GR, tssRegion=c(-1000, 1000), 
                         TxDb=TxDb.Scerevisiae.UCSC.sacCer3.sgdGene, 
                         annoDb="org.Sc.sgd.db")
```


### Importing Peaks

MACS peak calls can be found in our specied output directory with the suffix and extension "_peaks.xls".
MACS peaks come as a tab separated file thinly disguised as a “.xls”.
In addition to the genomic coordinates of peaks, these files contain useful information on the samples, parameters and version used for peak calling at the top.

### Filtering **blacklisted** regions

### Peak annotation

## Visualization

### Assess Alignment with IGV

Another method for assessing the quality of your alignment is to
visualize the alignment using a genome browser. For this workshop we
will be using the Integrative Genomics Viewer (IGV) from the Broad
Institute. You should already have this downloaded on your laptop. IGV
is an interactive tool which allows exploration of large, integrated
genomic datasets. It supports a wide variety of data types, including
array-based and next-generation sequence data, and genomic annotations,
which facilitates invaluable comparisons.

## Downstream Analysis

ChIP peaks in R: Let's generate a gene list corresponding to peaks that
appear in t20 minutes but not t0 minutes.

### Gene Set Enrichment

```{r}
# Load in MACS peaks
library(GenomicRanges)
macsPeaks <- "data/peaks/Mel_1_peaks.xls"
macsPeaks_DF <- read.delim(macsPeaks,comment.char="#")
macsPeaks_GR <- GRanges(seqnames=macsPeaks_DF[,"chr"],
                        IRanges(macsPeaks_DF[,"start"],macsPeaks_DF[,"end"]))
mcols(macsPeaks_GR) <- macsPeaks_DF[,c("abs_summit", "fold_enrichment")]
macsPeaks_GR[1:5,]

# Annotate peaks to genes
# library(TxDb.Mmusculus.UCSC.mm10.knownGene)
library(ChIPseeker)
peakAnno <- annotatePeak(macsPeaks_GR, tssRegion=c(-1000, 1000), 
                         TxDb=TxDb.Mmusculus.UCSC.mm10.knownGene, 
                         annoDb="org.Mm.eg.db")

annotatedPeaksGR <- as.GRanges(peakAnno)
annotatedPeaksDF <- as.data.frame(peakAnno)
annotatedPeaksDF[1:2, ]
```

We can extract the unique names of genes with peaks in their TSS by
subsetting the annotated GRanges and retrieving gene names from the
geneId column.

```{r}

annotatedPeaksGR_TSS <- annotatedPeaksGR[annotatedPeaksGR$annotation == "Promoter",
    ]
genesWithPeakInTSS <- unique(annotatedPeaksGR_TSS$geneId)
genesWithPeakInTSS[1:2]
```

Now, let's extract all genes which are included in the TxDb object to
use as our universe of genes for pathway enrichment.

```{r}
allGeneGR <- genes(TxDb.Mmusculus.UCSC.mm10.knownGene)
allGeneGR[1:2, ]

# save all of those gene_id's as a character object.
allGeneIDs <- allGeneGR$gene_id
```

#### Gene Ontology

```{r}
library(clusterProfiler)
library(org.Mm.eg.db)
GO_result <- enrichGO(gene = genesWithPeakInTSS, universe = allGeneIDs, OrgDb = org.Mm.eg.db,
    ont = "BP")

# convert to dataframe and print results
GO_result_df <- data.frame(GO_result)
GO_result_df[1:5, ]
```

#### KEGG

```{r}
KEGG_result <- enrichKEGG(gene = genesWithPeakInTSS, universe = allGeneIDs, OrgDb = org.Mm.eg.db)

# convert to dataframe and print results
KEGG_result_df <- data.frame(KEGG_result)
KEGG_result_df[1:5, ]
```

## Motif Analysis

The MEME-suite that we used in a previous motif analysis exercise has a
specific algorithm for ChIP-seq analysis, called MEME-ChIP

```{r}
# MEME-ChIP
```

We can use Meme to analyze the promoters of those genes corresponding to
enrichment peaks.

# Analysis: Motif Discovery for *msn2/4*∆∆ vs WT Response to EtOH

## Retrieve LogFC and FDR values

Let's load in the `DE_yeast_TF_stress.txt` file containing logFC and FDR
values for a variety of yeast strains and stress conditions.

```{r load-FClist}
# Load gene file used in clustering
FC_list <- readr::read_tsv(
  "https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/DE_yeast_TF_stress.txt.gz",
  name_repair = "universal"
) 
```

## Selecting an Ensembl BioMart database and dataset

```{r}
ensembl <- useEnsembl(biomart = "genes")
ensembl
```

Not we have loaded the "gene" database, but haven't selected a dataset
yet. Let's find the one we want:

```{r}
searchDatasets(mart = ensembl, 
               pattern = "scerevisiae")
```

So the dataset needs to be "scerevisiae_gene_ensembl" for yeast. Can you
find it for your organism?

```{r}
# Assign ensembl with the desired dataset
ensembl <- useEnsembl(biomart = "genes", 
                      dataset = "scerevisiae_gene_ensembl")
```

## Retrieve Upstream Sequences

```{r}
# Retrieve the ORF IDs included in the dataset
ORFs_in_analysis = FC_list$ID

# Get the upstream sequences for each gene and save in data.frame
seq <- getSequence(id = ORFs_in_analysis,
                 type="ensembl_gene_id",
                 seqType="coding_gene_flank",
                 upstream=500, 
                 mart=ensembl,
                 useCache = TRUE)

# Filter out rows with no sequence found
seq <- seq |> filter(coding_gene_flank != "Sequence unavailable")

# Display obtained sequences
glimpse(seq)
```

Now we have the 500bp upstream sequences for (almost) all of the genes
in the genome. Note that for yeast, this isn't too much data for a
laptop. If you're working with a larger genome, you might need to subset
the gene list down just to the genes in your gene list.

# Motif Analysis for Genes Downregulated in EtOH Response

In order to continue, we need a list of genes.

What gene list do you think has the most interesting biological meaning
for motif analysis? One comparison to consider is the genes that are
most different in the EtOH response between WT and *msn2/4*∆∆ samples.
Let's get that list of genes with large magnitude and statistically
significant negative logFC values now:

```{r}
# Create gene list for downregulated genes
msn24_EtOH_down <- FC_list |>
  dplyr::filter(logFC..WT.v.msn24.mutant..EtOH.response < -2) |>
  dplyr::filter(FDR..WT.v.msn24.mutant..EtOH.response<0.01) |>
  dplyr::select(ID) %>%
  # add the upstream sequences as a new column
  left_join(seq, by=c("ID" = "ensembl_gene_id")) |>
  drop_na("coding_gene_flank")

# Glimpse at the genes identified.
glimpse(msn24_EtOH_down)
```

For MEME analysis, the gene list needs to be formatted like a fasta
file. Here is how we can do that:

```{r}
# create Biostrings object
msn24_EtOH_down_fa <- Biostrings::DNAStringSet(msn24_EtOH_down$coding_gene_flank)
# Add gene names
names(msn24_EtOH_down_fa) <- msn24_EtOH_down$ID
```

Let's create a folder to which we can save output files.

```{r}
# Choose output directory for the output files to be saved
out_dir <- path.expand("~/Desktop/Genomic_Data_Analysis/Analysis/memes/")

# Create out_dir directory if doesn't already exist
if (!dir.exists(out_dir)) {
  dir.create(out_dir, recursive = TRUE)
}
```

## Run Meme enrichment

This was the first algorithm developed in the MEME-suite, and is still
widely used. However, it is not always the best approach. MEME is
recommended when you have fewer than 50 sequences, while STREME is
recommended when you have more. Also, the default parameter settings are
often **not** the best options depending on your organism (e.g, bacteria
tend to have longer motifs). We can adjust these settings in class to
parameters better suited to our data (based on biological domain
knowledge). See all of the parameter options at:
<https://meme-suite.org/meme/doc/meme.html>

```{r}
# Run Meme
meme_msn24_EtOH_down <- runMeme(msn24_EtOH_down_fa, 
        minw = 8, # default is 8, for yeast I use 5
        maxw= 50, #default is 50, for yeast I use 20
        mod= "zoops", #zero or one occurence per sequence
        parse_genomic_coord=FALSE,
        silent=F,
        outdir = path.expand(paste0(out_dir, "meme_msn24_EtOH_down"))
        )

# Display Meme results
meme_msn24_EtOH_down
```

## Run STEME enrichment

STEME is a newer MEME suite tool, that is better suited to looking for
shorter motifs which are common in Eukaryotes.

For `runStreme`, properly setting the `control` parameter is key to
discovering biologically relevant motifs. Often, using
`control = "shuffle"` will produce a suboptimal set of motifs; however,
some discriminative analysis designs don't have proper "control" regions
other than to shuffle.

For our analysis, we can use the promoter sequences from the entire
genome as a background to model the null distribution, let's create an
object in R with all of the 500bp upstream sequences from `seq` to use
as a control.

```{r}
# create a DNAStringSet object from our FC_list we created above.
background_fa <- DNAStringSet(left_join(FC_list,seq, by=c("ID" = "ensembl_gene_id")) |>
                                       drop_na("coding_gene_flank") |> pull(coding_gene_flank))
# add gene names
names(background_fa) <- left_join(FC_list,seq, by=c("ID" = "ensembl_gene_id")) |>
                                       drop_na("coding_gene_flank") |> pull(ID)
```

```{r}
# Run Streme
streme_msn24_EtOH_down <- runStreme(msn24_EtOH_down_fa, 
        control= background_fa,
        minw = 8, # default is 8, for yeast I use 5
        maxw= 15, #default is 15, for yeast i use 20
        parse_genomic_coord=FALSE,
        silent=TRUE,
        outdir = path.expand(paste0(out_dir, "streme_msn24_EtOH_down"))
        )

# Display Streme results
streme_msn24_EtOH_down
```

## Run TomTom analysis

Now, we can see if any of those identified motifs correspond to known
motifs in databases. The TomTom algorithm, part of the MEME-suite,
allows us to just that, comparing our identified motifs to known motifs
in annotation databases.

First, we need to download the YEASTRACT database file called
(YEASTRACT_20130918.meme). We will pull this file from Github, but you
can see and download all of the available databases at:
<https://meme-suite.org/meme/doc/download.html>.

```{r}
# Download YEASTRACT database .meme

# Define URL where data is located
URL_to_download <-
  "https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/reference/YEAST/YEASTRACT_20130918.meme"

# Choose desired destination for the reference database file
db_destination <-
  path.expand("~/Desktop/Genomic_Data_Analysis/Reference/YEASTRACT_20130918.meme")

# Download the file and save to db_destination
curl::curl_download(
  url = URL_to_download,
  destfile = db_destination,
  quiet = FALSE,
  mode = "wb"
)
```

```{r}
# Run TomTom on motifs found by runMeme()
meme_tomtom_msn24_EtOH_down <-
  runTomTom(
    input = meme_msn24_EtOH_down,
    norc = TRUE,
    thresh = 10,
    motif_pseudo = 0.1,
    database = db_destination,
    outdir = path.expand(paste0(out_dir, "tomtom_meme_msn24_EtOH_down"))
  )

# View Meme TomTom results
view_motifs(meme_tomtom_msn24_EtOH_down$best_match_motif)
```

Go to the `out_dir` directory on your computer, and open the tomtom.html
file. How convincing are those matches? With the default options, I'm
not impressed.

Let's run TomTom on the output of the `runStreme()` command above, and
see what we find.

```{r}
# Run TomTom on motifs found by runStreme()
streme_tomtom_msn24_EtOH_down <-
  runTomTom(
    input = streme_msn24_EtOH_down,
    norc = TRUE,
    thresh = 10,
    motif_pseudo = 0.1,
    database = db_destination,
    outdir = path.expand(paste0(out_dir, "tomtom_streme_msn24_EtOH_down"))
  )

# View Streme TomTom results
view_motifs(streme_tomtom_msn24_EtOH_down$best_match_motif,
            relative_entropy = FALSE, 
            normalise.scores = TRUE, 
            use.type = "ICM", 
            method = "WPCC",
            tryRC = FALSE)
```

It can sometimes be helpful to manually look at the alignments to see if
there's anything unexpected going on. We can use the command
`view_tomtom_hits()` to do this. The figures aren't publication quality,
but can be useful to see.

```{r}
view_tomtom_hits(streme_tomtom_msn24_EtOH_down, top_n = 3)
```

Cool! We see Msn2/4 promoter sequence motif is strongly enriched in the
promoter sequences of the genes that are lower in Msn2/4∆∆ vs WT
response to EtOH.

Let's do a sanity check, and do the exact same thing but for genes that
were *higher* in the same contrast, and see what enrichments if any are
found. We can put just the code we need:

```{r motif-Msn24EtOH_up}
# Create gene list
msn24_EtOH_up <- FC_list |>
  # I want more than 8 genes, so I lowered the FC cutoff
  filter(logFC..WT.v.msn24.mutant..EtOH.response > 1) |>
  filter(FDR..WT.v.msn24.mutant..EtOH.response<0.01) |>
  dplyr::select(ID) %>%
  # add the upstream seqs as a new column
  left_join(seq, by=c("ID" = "ensembl_gene_id")) |>
  drop_na("coding_gene_flank")

# create Biostrings object
msn24_EtOH_up_fa <- DNAStringSet(msn24_EtOH_up$coding_gene_flank)
# add gene names
names(msn24_EtOH_up_fa) <- msn24_EtOH_up$ID


# we already have background genes, so don't need to put that code again...

# Run Streme
streme_msn24_EtOH_up <- runStreme(msn24_EtOH_up_fa, 
        control= background_fa,
        # control= "shuffle",
        minw = 5, # default is 8, for yeast I use 5
        maxw= 20, #default is 15, for yeast I use 20
        parse_genomic_coord=FALSE,
        silent=TRUE,
  outdir = path.expand(paste0(out_dir, "streme_msn24_EtOH_up"))
        )

# Run TomTom analysis
streme_tomtom_msn24_EtOH_up <- runTomTom(
  input = streme_msn24_EtOH_up,
  norc = TRUE,
  thresh = 10,
  motif_pseudo = 0.1,
  database = db_destination,
  outdir = path.expand(paste0(out_dir, "tomtom_streme_msn24_EtOH_up"))
  )
```

Are Msn2/4 motifs enriched here? What biological meaning can we take
away from this?

# *skn7*∆ exposed to salt.

Now, let's take a look another mutant from this study exposed to a
different stressor.

```{r motif-skn7NaCl}
# create gene list
skn7_NaCl_down <- FC_list |>
  filter(logFC..WT.v.skn7.mutant..NaCl.response < -2) |>
  filter(FDR..WT.v.skn7.mutant.NaCl.response<0.00001) |>
  dplyr::select(ID) %>%
  # add the upstream seqs as a new column
  left_join(seq, by=c("ID" = "ensembl_gene_id")) |>
  drop_na("coding_gene_flank")

# create Biostrings object
skn7_NaCl_down_fa <- DNAStringSet(skn7_NaCl_down$coding_gene_flank)
# add gene names
names(skn7_NaCl_down_fa) <- skn7_NaCl_down$ID

# we already have background genes, so don't need to put that code again...

# Run Streme
streme_skn7_NaCl_down <- runStreme(skn7_NaCl_down_fa, 
        control= background_fa,
        # control= "shuffle",
        minw = 8, # default is 8, for yeast I use 5
        maxw= 15, #default is 15, for yeast I use 20
        evalue=TRUE,
        parse_genomic_coord=FALSE,
        silent=TRUE,
        outdir = path.expand(paste0(out_dir, "streme_skn7_NaCl_down"))
        )

# Run TomTom analysis
streme_tomtom_skn7_NaCl_down <- runTomTom(
  input = streme_skn7_NaCl_down,
  # norc = TRUE,
  thresh = 20,
  motif_pseudo = 0.1,
  database = db_destination,
  outdir = path.expand(paste0(out_dir, "tomtom_streme_skn7_NaCl_down"))
  )

```

Notice we have fewer genes this time, let's try meme instead

```{r}
# Run Meme
meme_skn7_NaCl_down <- runMeme(
  skn7_NaCl_down_fa,
  # control= "shuffle", #background_fa,
  # objfun="de",
  parse_genomic_coord = FALSE,
  minw = 5,
  maxw = 20,
  markov_order = 2,
  mod= "zoops", #zero or one occurence per sequence
  seed = 0,
  dna = T,
  revcomp = T,
  evt = 0.1,
  outdir = path.expand(paste0(out_dir, "meme_skn7_NaCl_down"))
)

# Run TomTom analysis
meme_tomtom_skn7_NaCl_down <- runTomTom(
  input = meme_skn7_NaCl_down,
  # norc = TRUE,
  thresh = 10,
  motif_pseudo = 0.1,
  min_overlap = 5,
  database = db_destination,
  outdir = path.expand(paste0(out_dir, "tomtom_meme_skn7_NaCl_down"))
  )
```

# Questions

1.  What is the difference in motifs when you change the settings for
    analyzing the msn2/4 mutant vs wild-type ethanol response using
    "zoops" or "anr" as the setting?

2.  Perform MEME and STREME on the wild-type salt response and wild-type
    ethanol response (using a log2 FC of 3 and FDR \< 0.01) to identify
    motifs in genes that are strongly induced for each stress, and then
    follow that analysis with TOMTOM. What TFs may be shared and what
    TFs may be different between the two stress responses?

Be sure to knit this file into a pdf or html file once you're finished.

System information for reproducibility:

```{r session-info}
pander::pander(sessionInfo())
```
