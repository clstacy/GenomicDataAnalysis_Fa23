{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Running Salmon on the UARK AHPCC\"\n",
        "author: \"Carson Stacy & Jeffrey Lewis\"\n",
        "format: html\n",
        "date: \"`r Sys.Date()`\"\n",
        "editor: visual\n",
        "execute:\n",
        "  eval: false\n",
        "---"
      ],
      "id": "e61f3caf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a tutorial for using the provided code to run salmon mapper on the UARK HPC. The code can be modified to analyze your own data. First, let's start recall how to log on to the HPC.\n",
        "\n",
        "\n",
        "```{bash login}\n",
        "#| eval: false\n",
        "ssh youruarkusername@hpc-portal2.hpc.uark.edu\n",
        "```\n",
        "\n",
        "\n",
        "To log on, we:\n",
        "\n",
        "1.  Open a terminal window\n",
        "\n",
        "    a.  on Windows: use either Git Bash or WSL terminal. There's also PuTTy, but that's not used much anymore\n",
        "\n",
        "    b.  on MacOS/Linux: you can run salmon on your own PC, but can also use the HPC. Just use your usual terminal.\n",
        "\n",
        "2.  Run the code above, being sure to change `youruarkusername` to your uark username. It will ask you to enter your uark password to log in.\n",
        "\n",
        "    a.  If you're not on campus wifi, you'll either need to use the GlobalProtect VPN that the campus provides, or run the same code above with `-p2022` at the end. It'll ask for your password, make sure your you, and then kick. you out. then run the usual log in code again and you'll be able to log in. This resets about every 48 hours, last I checked.\n",
        "\n",
        "3.  Now that you're logged on to the HPC, you will be located in your home folder. This code assumes you haven't done a lot of work on the HPC before, so it should work regardless of how you've set up your system. We can save our script and submit our job on the HPC from here.\n",
        "\n",
        "4.  We need to create a script that submits the code to the HPC system to run when a computing node is available. A script for doing so is below. You'll need to copy the below code, and save it into a new file (instructions for doing this are below the script.)\n",
        "\n",
        "\n",
        "    ```{bash launch_salmon.slurm, eval=FALSE}\n",
        "    #| eval: false\n",
        "    #!/bin/bash\n",
        "    #SBATCH --job-name=salmon_run_template\n",
        "    #SBATCH --partition=comp01  # Replace with the appropriate partition\n",
        "    #SBATCH --nodes=1                 # Number of CPU machines to allocate\n",
        "    #SBATCH --cpus-per-task=32         # Number of CPU cores to allocate\n",
        "    #SBATCH --time=01:00:00           # Maximum runtime (hours:minutes:seconds)\n",
        "    #SBATCH --output=out.salmon_%j    # Output file\n",
        "    #SBATCH --error=err.salmon_%j     # Error file\n",
        "\n",
        "    # Define variables\n",
        "    NCORES=32\n",
        "    FQ_DATA_DIR=\"/storage/$USER/home/Genomic_Data_Analysis/Data/Trimmed_fastq_files\"\n",
        "    SALMON_OUT_DIR=\"/storage/$USER/home/Genomic_Data_Analysis/Data/Counts/Salmon\"\n",
        "    REFERENCE_DIR=\"/storage/$USER/home/Genomic_Data_Analysis/Reference\"\n",
        "    TRANSCRIPTOME=\"Saccharomyces_cerevisiae.R64-1-1.cdna.all.fa.gz\"\n",
        "    GENOME=\"Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz\"\n",
        "    INDEX=index_salmon_Saccharomyces_cerevisiae.R64-1-1 # replace with desired name of your salmon index\n",
        "    EXPERIMENTNAME=\"yeast\" # name you'd like the output file to include\n",
        "\n",
        "    CLASS_EXERCISE=true\n",
        "    # NOTE: make sure you have put your trimmed fastq.gz files into $FQ_DATA_DIR if not using class files.\n",
        "\n",
        "    # Load any necessary modules or activate your virtual environment if needed\n",
        "    module purge\n",
        "    # module load gcc-11.2.1/SKYLAKEX/salmon/1.9.0  # modify as necessary\n",
        "    # below is a command to run an older version of salmon, that doesn't have bugs of 1.9.0\n",
        "    # it has different bugs instead. so I don't want to use it.\n",
        "    # module load salmon/1.4.0\n",
        "\n",
        "    # load in a python + anaconda module\n",
        "    module load python/3.12-anaconda\n",
        "\n",
        "    # activate conda\n",
        "    . /share/apps/python/anaconda-3.12/bin/activate\n",
        "    conda activate\n",
        "\n",
        "    # ensure conda channels are set up\n",
        "    conda config --add channels defaults\n",
        "    conda config --append channels bioconda\n",
        "    conda config --append channels conda-forge\n",
        "    conda config --set channel_priority strict\n",
        "\n",
        "    # create a conda environment for salmon\n",
        "    if conda info --envs | grep -q salmon; then echo \"environment 'salmon' already exists\"; else conda create -y -n salmon -c conda-forge -c bioconda salmon=1.10.2; fi\n",
        "\n",
        "    # activate conda environment with salmon\n",
        "    conda activate salmon\n",
        "\n",
        "    # Create the reference genome dir if it doesn't already exist\n",
        "    mkdir -p $REFERENCE_DIR\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    mkdir -p $SALMON_OUT_DIR\n",
        "\n",
        "    # Make the stated fastq file dir if doesn't already exist.\n",
        "    mkdir -p $FQ_DATA_DIR\n",
        "\n",
        "    # Navigate to the input directory\n",
        "    cd $FQ_DATA_DIR\n",
        "\n",
        "    # if using this for class, download data files into FQ_DIR\n",
        "    if [ \"$CLASS_EXERCISE\" = true ] ; then\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_MOCK_REP1_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_MOCK_REP2_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_MOCK_REP3_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_MOCK_REP4_R1.fastq.gz\n",
        "    \t# WT EtOH\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_ETOH_REP1_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_ETOH_REP2_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_ETOH_REP3_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_WT_ETOH_REP4_R1.fastq.gz\n",
        "    \t# msn2/4dd unstressed (mock)\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_MOCK_REP1_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_MOCK_REP2_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_MOCK_REP3_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_MOCK_REP4_R1.fastq.gz\n",
        "    \t# msn2/4dd EtOH\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_ETOH_REP1_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_ETOH_REP2_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_ETOH_REP3_R1.fastq.gz\n",
        "    \tcurl -L -O https://github.com/clstacy/GenomicDataAnalysis_Fa23/raw/main/data/ethanol_stress/fastq_trimmed/YPS606_MSN24_ETOH_REP4_R1.fastq.gz\n",
        "    fi\n",
        "\n",
        "    # return to where we were\n",
        "    cd -\n",
        "\n",
        "    ## Download the reference genome and transcriptome if not already in ref dir\n",
        "\n",
        "    # Define the URL of reference transcriptome (latest from ensembl)\n",
        "    url=\"ftp://ftp.ensembl.org/pub/release-110/fasta/saccharomyces_cerevisiae/cdna/$TRANSCRIPTOME\"\n",
        "\n",
        "    # Check if the file already exists at the destination location\n",
        "    if [ ! -f \"$REFERENCE_DIR/$TRANSCRIPTOME\" ]; then\n",
        "        echo \"Reference transcriptome not found, downloading...\"\n",
        "        # If the file does not exist, download it using curl\n",
        "        curl -o \"$REFERENCE_DIR/$TRANSCRIPTOME\" \"$url\"\n",
        "        echo \"Downloading finished\"\n",
        "    else\n",
        "        echo \"Transcriptome file already exists at $REFERENCE_DIR. Skipping download.\"\n",
        "    fi\n",
        "\n",
        "\n",
        "    # Define the URL of reference genome (latest from ensembl)\n",
        "    url=\"ftp://ftp.ensembl.org/pub/release-110/fasta/saccharomyces_cerevisiae/dna/$GENOME\"\n",
        "\n",
        "    # Check if the file already exists at the destination location\n",
        "    if [ ! -f \"$REFERENCE_DIR/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz\" ]; then\n",
        "        echo \"Reference genome not found, downloading...\"\n",
        "        # If the file does not exist, download it using curl\n",
        "        curl -o \"$REFERENCE_DIR/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz\" \"$url\"\n",
        "        echo \"Downloading finished\"\n",
        "    else\n",
        "        echo \"Genome file already exists at $REFERENCE_DIR. Skipping download.\"\n",
        "    fi\n",
        "\n",
        "\n",
        "    # These two commands generate a decoy.txt file from the genome we downloaded\n",
        "    grep \"^>\" <(gunzip -c $REFERENCE_DIR/$GENOME) | cut -d \" \" -f 1 > $REFERENCE_DIR/decoys.txt\n",
        "    sed -i.bak -e 's/>//g' $REFERENCE_DIR/decoys.txt\n",
        "\n",
        "    echo \"Decoy file generation complete\"\n",
        "\n",
        "    # Combine the transcriptome and genome into a single file for indexing\n",
        "    cat \"$REFERENCE_DIR/$TRANSCRIPTOME\" \"$REFERENCE_DIR/$GENOME\" > $REFERENCE_DIR/gentrome.fasta.gz\n",
        "\n",
        "    # move to our reference folder\n",
        "    cd $REFERENCE_DIR\n",
        "\n",
        "    # We can now create our salmon index\n",
        "    salmon index -t $REFERENCE_DIR/gentrome.fasta.gz -d $REFERENCE_DIR/decoys.txt -p $NCORES -i \"${REFERENCE_DIR}/${INDEX}\"\n",
        "\n",
        "    echo \"index generation complete\"\n",
        "\n",
        "    # move to the folder with our trimmed fastq files\n",
        "    cd $FQ_DATA_DIR\n",
        "\n",
        "    # Detect if both \"_R1\" and \"_R2\" files exist for the same sample to identify paired-end data\n",
        "\n",
        "    echo \"Initiating salmon counting...\"\n",
        "\n",
        "    for sampname_r1 in *_R1.fastq.gz; do\n",
        "        sampname=\"${sampname_r1%%_R1*}\"\n",
        "        r1=\"$sampname_R1\"\n",
        "        r2=\"${sampname}_R2.fastq.gz\"\n",
        "\n",
        "        if [ -f \"$r2\" ]; then\n",
        "            # Paired-end data\n",
        "            echo \"Processing paired-end sample $sampname\"\n",
        "    \tsalmon quant -i \"${REFERENCE_DIR}/${INDEX}\" \\\n",
        "                -l A \\\n",
        "    \t    -1 ${sampname}_R1.fastq.gz \\\n",
        "                -2 ${sampname}_R2.fastq.gz \\\n",
        "                --useVBOpt \\\n",
        "                -p $NCORES \\\n",
        "                --validateMappings \\\n",
        "                -o $SALMON_OUT_DIR/${sampname}_quant\n",
        "        else\n",
        "            # Single-end data\n",
        "    \techo \"Processing single-end sample $sampname\"\n",
        "            salmon quant -i \"${REFERENCE_DIR}/${INDEX}\" \\\n",
        "                -l A \\\n",
        "                -r ${sampname}_R1.fastq.gz \\\n",
        "                --useVBOpt \\\n",
        "                -p $NCORES \\\n",
        "                --validateMappings \\\n",
        "                -o ${SALMON_OUT_DIR}/${sampname}_quant\n",
        "        fi\n",
        "    done\n",
        "\n",
        "    # combine all of the output files into a merged count matrix\n",
        "    salmon quantmerge --quants $SALMON_OUT_DIR/*_quant --column numreads -o $SALMON_OUT_DIR/salmon.gene_counts.merged.$EXPERIMENTNAME.tsv\n",
        "\n",
        "    # remove the _mRNA from gene name\n",
        "    sed -i  -E 's/^([^\\t]+)_mRNA(\\t|$)/\\1\\2/' \"$SALMON_OUT_DIR/salmon.gene_counts.merged.$EXPERIMENTNAME.tsv\"\n",
        "\n",
        "    # we can also create a table of tpm values per gene by changing the --column flag\n",
        "    salmon quantmerge --quants ${SALMON_OUT_DIR}/*_quant --column tpm \\\n",
        "              -o \"${SALMON_OUT_DIR}/salmon.gene_tpm.merged.${EXPERIMENTNAME}.tsv\"\n",
        "\n",
        "    # remove the _mRNA from gene name for tpm file as well.\n",
        "    sed -i  -E 's/^([^\\t]+)_mRNA(\\t|$)/\\1\\2/' \"${SALMON_OUT_DIR}/salmon.gene_tpm.merged.${EXPERIMENTNAME}.tsv\"\n",
        "\n",
        "    echo \"Salmon job completed.\"\n",
        "    ```\n",
        "\n",
        "\n",
        "5.  Once you've copied all of the code (there should be a button in the top right corner of the code),\n",
        "\n",
        "    a.  go into your terminal window connected to the HPC and type `cd ~` and press enter. This makes sure you are in your home directory\n",
        "\n",
        "    b.  Type `nano launch_salmon.slurm` and press enter. This opens a text editor in command line, creating a new empty file with the given name.\n",
        "\n",
        "    c.  Right-click on the terminal, and click \"paste\". This should paste all of your code into this new file.\n",
        "\n",
        "    d.  Simultaneously press `Ctrl+O` to save the file, and then type `Ctrl+X` to exit this text editor\n",
        "\n",
        "    e.  type `cat launch_salmon.slurm` , you should see a couple hundred lines of code appear in your terminal. This should be the same code we see above.\n",
        "\n",
        "6.  Great, you have your script for running salmon on the HPC ready to go. To submit this script to the queue to be run, we type `sbatch launch_salmon.slurm` and press enter.\n",
        "\n",
        "7.  Depending on how busy the HPC is, it might take some time to run your job. To see if your job has started yet, you can run `squeue -u $USER`, which let's us know if R for running (and how long), or PD for pending (in the queue behind other jobs).\n",
        "\n",
        "8.  What does this script create? You'll see the job itself creates output files called out.salmon\\_###### and err.salmon\\_###### where the numbers are your submitted computing job's number. You don't need any information in these files for this script, but they are very useful for troubleshooting. You'll also see a new folder has been created in your home directory called Genomic_Data_Analysis. Inside that folder, you'll see reference and data folders. The reference folder has files the script has downloaded to map to. The Data folder has the raw subsampled fastq files we used in class for an input to map, and the final outputs are in the Data/Counts/Salmon folder, labeled as `salmon.gene_counts.merged.yeast.tsv` and `salmon.gene_tpm.merged.yeast.tsv` . These are the files we can use for subsequent differential expression analysis.\n",
        "\n",
        "9.  When you're done with your session on the HPC, you can log out typing `exit` in the terminal, and you're all good.\n",
        "\n",
        "10. If you want to move those files to your computer, you can use the HPC gui by going in your browser to hpc-portal2.hpc.uark.edu and clicking Files, and finding the file in the given folder. You should then be able to download them to your computer. It's also possible to move them with code using the `scp` command. If you know how to do that, it's great! Otherwise, it might be easier to use the GUI.\n",
        "\n",
        "The script is commented with what all it does. If you have questions, reach out and I can add more useful information below."
      ],
      "id": "04e36a24"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}